{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084ead5e-9d54-4a73-86cf-e185788db338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from video2image import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751a7601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88bad39b-6fcd-44cd-9289-6a803d127f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/image/0\n",
      " Video Duration is \u001b[1;33m0hr: 1min: 54sec \u001b[00m\n",
      " The input Video FPS is 60 frames/sec\n",
      " Capture rate is default FPS of input video i.e 60 frames/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m Capturing Frames... \u001b[00m: 6847iter [02:18, 49.45iter/s]                                                                                                     \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32;40m Done. Total frames captured: 6847 \u001b[00m\n",
      "raw_data/image/1\n",
      " Video Duration is \u001b[1;33m0hr: 2min: 25sec \u001b[00m\n",
      " The input Video FPS is 60 frames/sec\n",
      " Capture rate is default FPS of input video i.e 60 frames/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m Capturing Frames... \u001b[00m: 8720iter [03:12, 45.23iter/s]                                                                                                     \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32;40m Done. Total frames captured: 8720 \u001b[00m\n",
      "raw_data/image/2\n",
      " Video Duration is \u001b[1;33m0hr: 2min: 36sec \u001b[00m\n",
      " The input Video FPS is 60 frames/sec\n",
      " Capture rate is default FPS of input video i.e 60 frames/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m Capturing Frames... \u001b[00m: 100%|██████████████████████████████████████████████████████████████████████████████████████▉| 9419/9420 [03:01<00:00, 51.81iter/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32;40m Done. Total frames captured: 9419 \u001b[00m\n",
      "raw_data/image/3\n",
      " Video Duration is \u001b[1;33m0hr: 3min: 20sec \u001b[00m\n",
      " The input Video FPS is 60 frames/sec\n",
      " Capture rate is default FPS of input video i.e 60 frames/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m Capturing Frames... \u001b[00m: 100%|█████████████████████████████████████████████████████████████████████████████████████| 12000/12000 [03:48<00:00, 52.54iter/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32;40m Done. Total frames captured: 12000 \u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video2image('raw_data/mov','raw_data/image/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f0f501-5e44-45ae-b5af-fd15fec632e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5b6895-eb84-489a-91b5-83ebc8580a64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:[0.34509525 0.34218973 0.32864692]\n",
      "std:[0.27537261 0.27791566 0.27557457]\n"
     ]
    }
   ],
   "source": [
    "mean,std = get_mean_std('raw_data/image/1',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e498275d-fe94-4c00-9a25-1d9b39caa04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34509525, 0.34218973, 0.32864692])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aed4f7d-0730-486c-a79b-d8c77914987f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27537261, 0.27791566, 0.27557457])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9194fe36-ad3b-42fd-b9f4-c7288a7e6a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformers = get_transformers(mean,std,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cda4c5b-0837-4799-93cf-06efb702ccca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Compose(\n",
       "     Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "     RandomHorizontalFlip(p=0.5)\n",
       "     RandomApply(\n",
       "     p=0.5\n",
       "     <preprocessing.RandomExposure object at 0x0000028F60FF8D90>\n",
       " )\n",
       "     RandomApply(\n",
       "     p=0.5\n",
       "     <preprocessing.RandomBrightness object at 0x0000028F60FF9210>\n",
       " )\n",
       "     RandomApply(\n",
       "     p=0.5\n",
       "     <preprocessing.RandomNoise object at 0x0000028F60FF9360>\n",
       " )\n",
       "     ToTensor()\n",
       "     Normalize(mean=[0.34509525 0.34218973 0.32864692], std=[0.27537261 0.27791566 0.27557457])\n",
       " ),\n",
       " 'val': Compose(\n",
       "     Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "     ToTensor()\n",
       "     Normalize(mean=[0.34509525 0.34218973 0.32864692], std=[0.27537261 0.27791566 0.27557457])\n",
       " ),\n",
       " 'test': Compose(\n",
       "     Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "     ToTensor()\n",
       "     Normalize(mean=[0.34509525 0.34218973 0.32864692], std=[0.27537261 0.27791566 0.27557457])\n",
       " )}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a7357a-aa3a-4567-86c0-4d67d45d3b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasetが既に存在するため、新規作成を行いません。\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "train,val,test = get_dataset(transform=transformers, image_root = 'raw_data/image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d47fd4c-9797-4531-bd69-5ae5afa33177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 66286\n",
      "    Root location: dataset\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomApply(\n",
      "               p=0.5\n",
      "               <preprocessing.RandomExposure object at 0x0000028F60FF8D90>\n",
      "           )\n",
      "               RandomApply(\n",
      "               p=0.5\n",
      "               <preprocessing.RandomBrightness object at 0x0000028F60FF9210>\n",
      "           )\n",
      "               RandomApply(\n",
      "               p=0.5\n",
      "               <preprocessing.RandomNoise object at 0x0000028F60FF9360>\n",
      "           )\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.34509525 0.34218973 0.32864692], std=[0.27537261 0.27791566 0.27557457])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2617d640-0db6-47da-97f1-d1e92a005476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takum\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\takum\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "resnet_module = PlResnetModule()\n",
    "pl_data_module = PlDataModule(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eeacee1-5755-4fe0-a401-d15b29bdb32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\takum\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1d384a-f4f6-4ec9-a1df-70cae15f8f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | model   | ResNet           | 21.3 M\n",
      "---------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.147    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takum\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'function' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_data_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[0;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    555\u001b[0m     ckpt_path,\n\u001b[0;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    558\u001b[0m )\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    932\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:978\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m--> 978\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:193\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:221\u001b[0m, in \u001b[0;36m_FitLoop.setup_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: resetting train dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_source\n\u001b[1;32m--> 221\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43m_request_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataloader, CombinedLoader):\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:328\u001b[0m, in \u001b[0;36m_request_dataloader\u001b[1;34m(data_source)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    The requested dataloader\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001b[39;00m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[39;00m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:298\u001b[0m, in \u001b[0;36m_DataLoaderSource.dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, pl\u001b[38;5;241m.\u001b[39mLightningDataModule):\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:162\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\esprots_researchtools\\eye_tracker\\eye_ai\\train.py:18\u001b[0m, in \u001b[0;36mPlDataModule.train_dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\lightning_fabric\\utilities\\data.py:330\u001b[0m, in \u001b[0;36m_wrap_init_method.<locals>.wrapper\u001b[1;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m store_explicit_arg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore_explicit_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, kwargs[store_explicit_arg])\n\u001b[1;32m--> 330\u001b[0m init(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pl_inside_init\u001b[39m\u001b[38;5;124m\"\u001b[39m, old_inside_init)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\torch\\utils\\data\\sampler.py:106\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\torch\\utils\\data\\sampler.py:114\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'function' has no len()"
     ]
    }
   ],
   "source": [
    "trainer.fit(resnet_module, pl_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1880ddc9-c6ba-4b7b-ac20-e33637bb2691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "No `test_step()` method defined to run `Trainer.test`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpl_data_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# テスト結果を出力する\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:706\u001b[0m, in \u001b[0;36mTrainer.test\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    704\u001b[0m     model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:749\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(model, test_dataloaders\u001b[38;5;241m=\u001b[39mdataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[0;32m    746\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    748\u001b[0m )\n\u001b[1;32m--> 749\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[0;32m    751\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:883\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector\u001b[38;5;241m.\u001b[39m_attach_model_callbacks()\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector\u001b[38;5;241m.\u001b[39m_attach_model_logging_functions()\n\u001b[1;32m--> 883\u001b[0m \u001b[43m_verify_loop_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m    886\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:44\u001b[0m, in \u001b[0;36m_verify_loop_configurations\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     42\u001b[0m     __verify_eval_loop_configuration(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mTESTING:\n\u001b[1;32m---> 44\u001b[0m     \u001b[43m__verify_eval_loop_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mPREDICTING:\n\u001b[0;32m     46\u001b[0m     __verify_eval_loop_configuration(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\esprots_researchtools-LbchKdBZ\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108\u001b[0m, in \u001b[0;36m__verify_eval_loop_configuration\u001b[1;34m(model, stage)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_step:\n\u001b[0;32m    107\u001b[0m     trainer_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m stage\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()` method defined to run `Trainer.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# check legacy hooks are not present\u001b[39;00m\n\u001b[0;32m    111\u001b[0m epoch_end_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: No `test_step()` method defined to run `Trainer.test`."
     ]
    }
   ],
   "source": [
    "\n",
    "result = trainer.test(resnet_module, datamodule=pl_data_module)\n",
    "    # テスト結果を出力する\n",
    "print(result)\n",
    "    # モデルを保存する\n",
    "torch.save(resnet_module.model.state_dict(), 'resnet_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
